{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d6446-6b74-400b-bd86-3e9cb11ef50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install --upgrade transformers\n",
    "!pip install transformers[sentencepiece]\n",
    "!pip install transformers[torch]\n",
    "!pip install einops\n",
    "!pip install openai\n",
    "!pip install evaluate\n",
    "!pip install torch\n",
    "!pip install tensorflow\n",
    "!pip install scikit-learn\n",
    "!pip install tf-keras\n",
    "!pip install accelerate -U\n",
    "!pip install sentencepiece\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d57412b-9d76-4e02-851d-e87f0e4f5ad3",
   "metadata": {},
   "source": [
    "Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110bb95-430f-4acc-9197-7f1f4e1c97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "from datasets import load_dataset\n",
    "# from google.colab import auth\n",
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "# from google.colab import drive\n",
    "import zipfile\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "\n",
    "import evaluate\n",
    "import torch.nn as nn\n",
    "import re\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae20b53-b324-4a37-9782-cdda4819c364",
   "metadata": {},
   "source": [
    "Load dataset and create sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83133f5e-f761-4c08-b9af-ca9b10ceeb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "def load_and_extract_dataset(zip_path):\n",
    "    # Create a temporary directory\n",
    "    temp_dir = '/tmp/dataset_extracted'\n",
    "    \n",
    "    # Ensure the directory is clean\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    os.makedirs(temp_dir)\n",
    "    \n",
    "    # Unzip the file to the temporary directory\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(temp_dir)\n",
    "\n",
    "    # Load the dataset from the extracted directory\n",
    "    dataset = load_from_disk(temp_dir)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e13206d-dc05-47e8-b170-02c1b1d35709",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_name = 'dataset.zip'\n",
    "dataset = load_and_extract_dataset(zip_name)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa57724-5e8d-487a-802c-99fb276c3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sampled_0 = []\n",
    "dataset_sampled_1 = []\n",
    "def sampleDataset(samples):\n",
    "    train_dataset = dataset['train']\n",
    "\n",
    "    dataset_sentiment_0 = train_dataset.filter(lambda x: x['label'] == 0)\n",
    "    dataset_sentiment_1 = train_dataset.filter(lambda x: x['label'] == 1)\n",
    "\n",
    "    dataset_sampled_0 = dataset_sentiment_0.shuffle().select(range(samples//2))\n",
    "    dataset_sampled_1 = dataset_sentiment_1.shuffle().select(range(samples//2))\n",
    "\n",
    "    dataset_combined = concatenate_datasets([dataset_sampled_0, dataset_sampled_1])\n",
    "\n",
    "    sampled_dataset = dataset_combined.shuffle()\n",
    "\n",
    "    print(\"Positive: \", sum(1 for example in sampled_dataset if example['label'] == 1))\n",
    "    print(\"Negative: \", sum(1 for example in sampled_dataset if example['label'] == 0))\n",
    "    print(sampled_dataset)\n",
    "\n",
    "    update_fn = partial(update_column, positivePrompt = positivePrompt, negativePrompt = negativePrompt)\n",
    "    sampled_dataset = sampled_dataset.map(update_fn, batched=False)\n",
    "    \n",
    "    return sampled_dataset\n",
    "\n",
    "\n",
    "def update_column(example, positivePrompt, negativePrompt):\n",
    "    usedPrompt = positivePrompt if example[\"label\"] == 1 else negativePrompt\n",
    "    # usedString = '\\n\\nPositive: ' if example [\"label\"] == 1 else '\\n\\nNegative: \"' \n",
    "    \n",
    "    example[\"text\"] = usedPrompt  + example[\"text\"] + '\"'\n",
    "    return example    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bb5344-fa54-4a91-8f71-9a714ff9b256",
   "metadata": {},
   "source": [
    "K-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0884f2-c3f2-4b2b-b239-e7740f3476c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positivePrompt = '''\n",
    "Generate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\n",
    "'''\n",
    "negativePrompt = '''\n",
    "Generate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: '''\n",
    "\n",
    "prompt = 'Generate one positive tweet and one negative tweet on a very specific topic. Ensure that each tweet is enclosed in straight quotation marks (\"\"). The positive tweet should express enthusiasm or praise, and the negative tweet should convey criticism or disappointment. Your comments should include specific features, aspects, or things that are praised/critisized.  \"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4898aa-de17-491b-9cc6-ba351e212283",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset = sampleDataset(1000)\n",
    "sampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3676388-e8e7-4e0b-b735-b22af4156ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positivePrompt += str(dataset_sampled_1[:k])\n",
    "positivePrompt += '''\\nEnsure your tweet is enclosed in straight double quotation marks. Provide ONLY one tweet. Positive: \"'''\n",
    "\n",
    "negativePrompt += str(dataset_sampled_0[:k])\n",
    "negativePrompt += '''\\nEnsure your tweet is enclosed in straight double quotation marks. Provide ONLY one tweet. Positive: \"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a631f-e50c-4576-b193-68ae62c26bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the dataset and pick K random entries\n",
    "def pick_random_entries(K):\n",
    "    random_entries = random.sample(list(sampled_dataset), K)\n",
    "\n",
    "    return random_entries\n",
    "\n",
    "k = 2\n",
    "\n",
    "random_entries = pick_random_entries(k)\n",
    "\n",
    "promptCreated = \"\"\n",
    "\n",
    "for entry in random_entries:\n",
    "  promptCreated += 'POSITIVE: \"' if entry['label'] == 1 else 'NEGATIVE: \"'\n",
    "  promptCreated += entry[\"text\"] + '\"\\n'\n",
    "print(promptCreated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67db4c8-5ee6-4016-a0bb-ca5b22c83822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteIrrelevent(s, prompt, isPositive):\n",
    "    s = s.replace(prompt, '')\n",
    "\n",
    "    # Find the index of the second double quotation mark\n",
    "    first_quote_index = s.find('\"')\n",
    "    if first_quote_index == -1:\n",
    "        # No double quotation mark found\n",
    "        return s\n",
    "    \n",
    "    second_quote_index = s.find('\"', first_quote_index + 1)\n",
    "    if second_quote_index == -1:\n",
    "        # Only one double quotation mark found\n",
    "        return s\n",
    "\n",
    "    findTweets(s, prompt)\n",
    "    \n",
    "    # Return the substring up to the second double quotation mark\n",
    "    return s[:second_quote_index + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa0f8a-a72c-4d4a-ac96-29d221775f21",
   "metadata": {},
   "source": [
    "Mistral 7b model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea0e73-68ae-4a82-8d49-3278d430eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "# model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# model_name = \"distilbert/distilbert-base-uncased\"\n",
    "GANtokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "GANmodel = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "GANmodel.load_state_dict(torch.load('model_state_dict.pth'))\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if(torch.cuda.is_available()):\n",
    "  GANmodel = GANmodel.cuda()\n",
    "\n",
    "if GANtokenizer.pad_token is None:\n",
    "    GANtokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765eff47-56f8-4408-b458-cd4e1df70429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rows_with_hashtags(dataset, column_name):\n",
    "    \"\"\"\n",
    "    Count how many rows in the Dataset contain a hashtag in the specified column.\n",
    "    \n",
    "    Parameters:\n",
    "    dataset (Dataset): The Dataset to search through.\n",
    "    column_name (str): The name of the column to search for hashtags.\n",
    "    \n",
    "    Returns:\n",
    "    int: The count of rows containing hashtags in the specified column.\n",
    "    \"\"\"\n",
    "    # Check if the column exists in the dataset\n",
    "    if column_name not in dataset.column_names:\n",
    "        raise ValueError(f\"Column '{column_name}' does not exist in the dataset.\")\n",
    "    \n",
    "    # Define a function to check if a string contains a hashtag\n",
    "    def contains_hashtag(text):\n",
    "        return isinstance(text, str) and '#' in text\n",
    "    \n",
    "    # Apply the function to the specified column and sum the results\n",
    "    count = sum(contains_hashtag(row[column_name]) for row in dataset)\n",
    "    \n",
    "    return count\n",
    "\n",
    "count_rows_with_hashtags(dataset[\"train\"], \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47175207-196f-4b87-96c3-7ecee12df071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promptModel(prompt, length):\n",
    "    inputs = GANtokenizer(prompt, return_tensors='pt').to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    outputs = GANmodel.generate(\n",
    "        inputs['input_ids'],\n",
    "        do_sample=True,\n",
    "        attention_mask=attention_mask,\n",
    "        num_return_sequences=1,\n",
    "        max_length=length,\n",
    "        temperature = 0.9, \n",
    "        top_p = 0.9, \n",
    "        repetition_penalty=1.2,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True\n",
    "    )\n",
    "\n",
    "    # Decode the generated text\n",
    "    text = GANtokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "    print(\"Generated Text:\", text)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass to get logits\n",
    "        logits = GANmodel(outputs.sequences).logits\n",
    "\n",
    "\n",
    "    return text, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed464c5e-8ad5-4430-8922-7ecdcfecccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = promptModel(negativePrompt, 66)\n",
    "# x = output[0]\n",
    "\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3999dad3-4210-46f4-ba88-34a75f318b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTweets(generated_text, isPositive):\n",
    "    output = generated_text.replace('“', '\"').replace('”', '\"')\n",
    "\n",
    "    if(isPositive):\n",
    "        positive_match = re.search(r'Positive:\\s*\"\\s*([^\"]*)\\s*\"', output, re.DOTALL)\n",
    "        positive_tweet = positive_match.group(1).strip() if positive_match else \"-1\"\n",
    "        return positive_tweet\n",
    "\n",
    "    else:\n",
    "        negative_match = re.search(r'Negative:\\s*\"\\s*([^\"]*)\\s*\"', output, re.DOTALL)\n",
    "        negative_tweet = negative_match.group(1).strip() if negative_match else \"-1\"\n",
    "        return negative_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6921a-261f-499a-8530-fc908c7f0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = findTweets(x, False)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5876af8-ccf8-4888-a5f2-2abba812ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAndExtractTweets(prompt, label, length):\n",
    "            \n",
    "    while True:\n",
    "        print(\"\\n\\nSTEP 1: INITAL PROMPT\")\n",
    "        text, logits = promptModel(prompt, length)\n",
    "        print(\"\\n\\nSTEP 2: TWEET SEARCH\")\n",
    "        tweet = findTweets(text, label == 1)\n",
    "        \n",
    "        if tweet != \"-1\" and len(tweet) > 0:\n",
    "            print(\"\\n\\nSTEP 3: RE PROMPTING\")\n",
    "            length = len(GANtokenizer.encode(tweet, add_special_tokens=True))\n",
    "            text, logits = promptModel(tweet, length + 1)  \n",
    "            return text, logits\n",
    "\n",
    "        print(\"\\n\\n\\nretry!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a057c60-ec01-4bb8-bf21-442eda28f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generateAndExtractTweets(positivePrompt, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805239a1-6b74-4fa2-8ea5-e18dc543f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from transformers import AdamW\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "  def __init__(self, vocab_size, embed_size):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "    self.lstm = nn.LSTM(embed_size, 128, batch_first=True)\n",
    "    self.fc = nn.Linear(128, 1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, input_ids):\n",
    "    embeds = self.embedding(input_ids)\n",
    "    _, (hidden, _) = self.lstm(embeds)\n",
    "    output = self.fc(hidden[-1])\n",
    "    return self.sigmoid(output)\n",
    "#generator and discriminator instantiation\n",
    "generator = GANmodel\n",
    "\n",
    "if(torch.cuda.is_available()):\n",
    "  discriminator = Discriminator(len(GANtokenizer), 768).cuda()\n",
    "else:\n",
    "    discriminator = Discriminator(len(GANtokenizer), 768)\n",
    "\n",
    "#optimizers\n",
    "optimizerG = AdamW(generator.parameters(), lr=5e-5)\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=5e-5)\n",
    "#loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "data_loader = torch.utils.data.DataLoader(sampled_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d2a22-8080-4fc1-b4e3-2424c3f5e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data_loader:\n",
    "    print(batch.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb3e36-d50a-4767-a2bc-d60d2e70c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeData(texts):\n",
    "    return GANtokenizer(texts, truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e600e-ee88-4acd-ac29-f85d4eb0d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for batch in data_loader:\n",
    "    print(batch) \n",
    "    i+=1\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552725e-2989-4e16-994a-9e18b880a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data_loader:\n",
    "        \n",
    "        # Convert the input batch into a PyTorch tensor and move to GPU\n",
    "    padded_inputs = GANtokenizer(batch['text'], padding=True, return_tensors=\"pt\", truncation=True)\n",
    "    real_text = padded_inputs['input_ids'].cuda()\n",
    "    print(real_text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc6e77-34da-4ed7-a2df-8b66b13e3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# For more accurate error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"PYTORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "\n",
    "batches = 1\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for batch in data_loader:\n",
    "        \n",
    "        # Convert the input batch into a PyTorch tensor and move to GPU\n",
    "        padded_inputs = GANtokenizer(batch['text'], padding=True, return_tensors=\"pt\", truncation=True)\n",
    "        real_text = padded_inputs['input_ids'].cuda()\n",
    "\n",
    "        # Generate fake text logits using noise input\n",
    "        noise = torch.randint(0, len(GANtokenizer), (1, 16)).cuda()\n",
    "        outputs = generator(noise)\n",
    "        fake_logits = outputs.logits.argmax(dim=-1).detach().cuda()  # Detach to avoid backpropagation\n",
    "        fake_logits_raw = outputs.logits.cuda()  # Raw logits before argmax for shape consistency\n",
    "        \n",
    "        # Reset gradients for discriminator\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        # Create real labels tensor and move to GPU\n",
    "        real_labels = torch.ones((real_text.size(0), 1), dtype=torch.float).cuda()\n",
    "\n",
    "        # Get discriminator's prediction on real text and calculate loss\n",
    "        real_output = discriminator(real_text)\n",
    "        lossD_real = criterion(real_output.view(-1, 1), real_labels)\n",
    "        \n",
    "        # Reshape fake logits to ensure correct shape\n",
    "        fake_logits = fake_logits.view(-1, 1).cuda()\n",
    "\n",
    "        # Get discriminator's prediction on fake text and calculate loss\n",
    "        fake_output = discriminator(fake_logits)\n",
    "        \n",
    "        # Create fake labels tensor and move to GPU\n",
    "        fake_labels = torch.zeros((fake_output.size(0), 1), dtype=torch.float).cuda()\n",
    "        \n",
    "        lossD_fake = criterion(fake_output, fake_labels)\n",
    "\n",
    "        # Combine real and fake losses for the discriminator\n",
    "        lossD = lossD_real + lossD_fake\n",
    "        lossD.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(discriminator.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizerD.step()\n",
    "\n",
    "        # Reset gradients for generator\n",
    "        generator.zero_grad()\n",
    "\n",
    "        # Generate new fake text logits\n",
    "        with torch.no_grad():\n",
    "            outputs = generator(noise)\n",
    "        fake_logits = outputs.logits.argmax(dim=-1).cuda()\n",
    "\n",
    "        # Get discriminator's assessment of the newly generated fake data\n",
    "        fake_output = discriminator(fake_logits.view(-1, 1).cuda())\n",
    "\n",
    "        real_labels = torch.ones((fake_output.size(0), 1), dtype=torch.float).cuda()\n",
    "\n",
    "        # Calculate the generator's loss\n",
    "\n",
    "        lossG = criterion(fake_output.view(-1, 1), real_labels)\n",
    "        lossG.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(generator.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizerG.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch}/{epochs}] Loss_D: {lossD.item():.4f} Loss_G: {lossG.item():.4f}')\n",
    "        print(\"BATCH NUMBER \" + str(batches))\n",
    "        batches+=1\n",
    "        del padded_inputs, real_text, noise, outputs, fake_logits, fake_logits_raw, real_labels, real_output, fake_labels, fake_output\n",
    "        # gc.collect(generation=2)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "torch.save(generator.state_dict(), 'model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d00bcd-eedb-452f-b412-d35f0db22154",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff48f1-ea34-4e4a-b3a3-ebf478669d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = GANtokenizer(positivePrompt, return_tensors='pt').to(device)\n",
    "attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "outputs = GANmodel.generate(\n",
    "    inputs['input_ids'],\n",
    "    do_sample=True,\n",
    "    attention_mask=attention_mask,\n",
    "    num_return_sequences=1,\n",
    "    max_length=100,\n",
    "    temperature = 0.9, \n",
    "    top_p = 0.9, \n",
    "    repetition_penalty=1.2,\n",
    "    output_scores=True,\n",
    "    return_dict_in_generate=True\n",
    ")\n",
    "\n",
    "# Decode the generated text\n",
    "text = GANtokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "with torch.no_grad():\n",
    "        # Forward pass to get logits\n",
    "        initial_logits = GANmodel(outputs.sequences).logits\n",
    "print(\"Generated Text:\", text)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "# Modify the generated text\n",
    "modified_text = findTweets(text, True)\n",
    "print(\"Modified Text:\", modified_text)\n",
    "\n",
    "# Tokenize the modified text\n",
    "modified_inputs = GANtokenizer(modified_text, return_tensors='pt').to(device)\n",
    "attention_mask = modified_inputs['attention_mask'].to(device)\n",
    "length = len(GANtokenizer.encode(modified_text, add_special_tokens=True)) + 1\n",
    "\n",
    "outputs = GANmodel.generate(\n",
    "    modified_inputs['input_ids'],\n",
    "    do_sample=True,\n",
    "    attention_mask=attention_mask,\n",
    "    num_return_sequences=1,\n",
    "    max_length=length,\n",
    "    temperature = 0.9, \n",
    "    top_p = 0.9,  \n",
    "    repetition_penalty=1.2,\n",
    "    output_scores=True,\n",
    "    return_dict_in_generate=True\n",
    ")\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "modified_text = GANtokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "\n",
    "# new_logits = outputs.scores\n",
    "\n",
    "with torch.no_grad():\n",
    "        # Forward pass to get logits\n",
    "        new_logits = GANmodel(outputs.sequences).logits\n",
    "\n",
    "print(\"Generated Text:\", modified_text)\n",
    "\n",
    "print(\"Logits Shape:\", new_logits)\n",
    "print(\"Logits Shape:\", initial_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7e3b5-493b-4477-9507-2519ee7bb5b8",
   "metadata": {},
   "source": [
    "BERT Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "696b5d08-3682-42bc-acd4-5d9cd9f6226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Well, bags of fun I\\'m going to have burning this lot off tonight    http://yfrog.com/0umftj\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @bmmcauliffe it wont let me upload a picture though \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @Hello_Candy Heh yar. And apparently most men aren\\'t creative. It\\'s a sad sad world \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nCould use a few more days down here  headed back to jawja in the a.m.!\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: really wants to go to warped tour this year.....    i hope my brother lets me.\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@tonfue  I am too!! ;) haha\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Ahhh another sucky wet weekend. Back to work I guess \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Why.) - â\\x80\\x9cWhy does my boyfriend pay attention to other galsÂ\\xa0?â\\x80? That was what made me so insecure  Well part... http://tumblr.com/xex22fzub\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@missgiggly If you \\'link me\\', it\\'ll make it easier. \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nJust got an email from Xbox Live with the subject &quot;Tonight, all will be revealed&quot;. Under 3 hours to go  #XboxE3\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Run fast and far...the pits of hell are attempting to swallow me!   I will not be a victim!  Not today sir!\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: I want him right beside me. \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@truesayian what a ball buster. its going to be festive indeed  some of my favorite bands will be there!\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @simplyjesslee Where were you?  I didn\\'t have much time and I couldn\\'t cover A &amp; B area   http://tokyokawaiietc.com/archives/2051\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: at work bored out of my mindddddd... ready to get off  and its only 12.\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @nataleat I will be at camp from June 1st to August 1st  But I am coming to Dallas in August. I will see you if it\\'s the last thing I do!\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nhas just bought loads of new clothes! \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Shopping for suits is hard \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: I seem to be having a bad hair day. Driving me nuts \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@tommcfly HAHA WE KNOW THIS TV SHOW!CASSETA E PLANETA,CAN\\'T WAIT TO SEE WHAT THAT GUYS WILL DO WITH U.  TAKE CARE TOM,GET WELL!\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Oh my word! It\\'s sooo cold in this house \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@silkcharm Hiya  You askin for me? Yep, I\\'m still on holiday in warm Canada. Others from NetworkPR are @joolliee or @robirwin\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Still waiting for a start date on the new job, guess I\\'ll have to ring back at two \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @JazzMX5 The part about her not being able to keep her eyes open cause of the pain killed me. \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@RebeccaLange As long as they taste good, that\\'s all the matters \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nPotato tacos @ Gerry.Nicoles pad &amp; watched a Japanese coachroach anime  the perfect marriage lol\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @LMangueArt My copy of &quot;Hollywood Boulevard&quot; got backordered. \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @popalockin sorry my friend, more studying for tomorrows test \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @carfullofpandas I wish I was as drunk as you but I am not. Witness my impeccable typing. \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Y is keyshia takin so long....this is the longest intermission ever \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@DonnieWahlberg I love you too! \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nHave just been watching CSI with my dear loving parents  and now I\\'m kind of bored as always XD\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: I must be going through a phase or something....I just don\\'t want to workout.  And it doesn\\'t help my mood....\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nAm plecat spre Craiova. Diseara live blogging pe Monden.info de la premii, of course  de la 8. Maine detalii  din culise si after party\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@Kaschua &quot;[You] don\\'t take good pictures \\'cuz [you] have the kind of beauty that moves.&quot;  \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Yeah, so today was pretty stupid. I\\'m impressed with what my girls got done, but there is still so much to do! Retail = Hell. \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n Goodmorning again! haha. ) uggh. i\\'m getting kinda hungry :|\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @Bertitude I considered that possibility since they were so far from the Bermuda Triangle. It\\'s scary they can\\'t find the plane, 228 ppl \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nwoot! A few more hrs till my bday! \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Wonders if she\\'ll ever meet him again and get to work with him on a film.  - http://tweet.sg\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @Chintan_Diver Thank you  \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: exams suck exams suck exams suck exams suck exams suck exams suck exams suck!! Entertain me, i have nothing to do but clean and study \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@tommcfly See some funny videos on Youtube \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: My twitterfon isnt working properly  goodnight , it better be better tommorow .\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nbtw MORNING bitches!  Can I haz my userpic back, stupid twitter???\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@blueparrot2 extreme makeover home edition!  lol\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@jodonohue Good morning \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @Jeh_Cee yeauuhhh. \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: the titanic exhibit was awesome. i survived the trip, but my brother died. \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nwishing i was somewhere else completely....i need to get away from everyone and everything for a little while! \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: my webcam died \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Im at the bank \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @mcclorybrin  boo i wont   thats  make me  sad\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@piaguanio he doesn\\'t have one actually.  (referring to David Cook)\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @PinchedPink Even I don\\'t grasp the concept. \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: started reading Vanishing Point and it\\'s pretty good so far! other than that, not really feeling like myself. \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Heading to connersville, IN to take ethan on a train ride for his b-day! Can\\'t believe he\\'ll be 3 tomorrow!  the zoo is tomorrow! Fun fun\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: is Burnt  Very Bad Times.....\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@swiftkaratechop  that\\'ll sure make my day! lol\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @siren223 sorry to hear about the bad days...   Would love to buy you a drink or something cool to help you feel better!\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@SisterRoma LOL that would make you horny. \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @steeZster: lol..no hoe, no hoe, no hoe..  btw, i kno wat i want. its up 2 God.. no matter how hard i try, i miss the way he made me feel \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@nafisa1 oh crap...lol well, it was fun to enter! \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@stevepurkiss  LOL.  Was it worth getting up today? \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@benchrisman Just curious about it, that\\'s all. \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: i only have 7 followers! how sad! \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nloveeeeeeee sleepin in  unpackin, relaxin, and watchin the hills tonight \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @suzyv Sorry to see you\\'ll not be at Glastonbury this year  It\\'s the highlight of my festival when you\\'re in that blue tent. Keep well x\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@tinchystryder hope amelle turns up this time! \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Finally I get to study... Can\\'t believe its 9 o\\'clock already... \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @blogbabygabby I loved pinky and the brain! and teenage mutant ninja turtles. They don\\'t make cartoons like that anymore. \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Bryce is out  ...Man this is the way to watch poker - condensed 1 hour programs are nuttin\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@foxandfriends  Yep! AND he should be MUZZLED by the Secret Service &amp; required to write contents of James 1:19 on a blackboard, 4x/day. \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nwow recorded an amazing track, ya i\\'m overwhelmed. so blessed to work with so talented f*ckin genius people \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nhttp://twitpic.com/6azzd - tuna belly / toro &amp; scallop sushi .. this tuna belly made me cry, it was so beautiful and delicious  sigh..!\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nIs Coooooking \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@inJenious Sounds good to me. Ta \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\npup play time  this is SO fun\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@keenkreations u can try dry ice \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nYes, I created a (local only) #drupal module called FunkyChicken. Now to find a valid use for it  http://tinyurl.com/lcpcc2\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: i wonder how many for mal-purposes.  \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @Ms_Brooklyn305 Black berry suxs \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@nkangel74 AWESOME! camera. BEAUTYFUL pic of Joe. Good job girl \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nI\\'m laughing and smiling so much @hypnophil has had to go and put the laptop on to see what he\\'s missing   He\\'s such a sweetheart\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: I don\\'t want to sit at home on prom night. Someone hang out with me \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@lifecruiser I\\'ll have another, thanks \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nHangin Out With My Buddy Wesley! Fisin to go play some Bball Its gunna b a good day \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @ichigojuice oh ok. I has twitterfox thanks to me noticing you used it. twitters easy now. but less Siwon sightings with twitterfox \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Time to get some groceries!!! \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nT3: Eugene Robinson\\'s on MSNBC\\'s &quot;Countdown&quot; often. I never get tired of @harrislacewell on @maddow. What\\'re they doing Sundays?  #jsticks\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @russchambers afraid I won\\'t be there tomorrow man. I\\'m enjoying a little time off.  sad face for missing you.\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@tanitaa After a nite full of random peeps, some local tweeps, many drinks and some magic tricks ... I am home. \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @jodifuckinrocks More like goodnight \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Low battery!!! Bad times \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@juliansimpson Have you considered writing, with @gibbzer, a compendium of your Tweets? \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: just saw the beyonce &quot;ego&quot; video.. damn it why havent i got tickets to see her \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Alec Wilder\\'s songs are so beautiful, they make me cry. Blackberry Winter was myself and Craig\\'s favourite song to do together \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nand i just found it for $3... \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: thunderstorms are cool, but not when the power goes out...... \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nWatched WALL-E... AGAIN.  Now checking out The Happening on Cinemax, then off the rents for the night. Safe trip boys! NYC\\'ll miss you.\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: wow, assignments already? It\\'s the first meeting of the subject and the instructors give us an assignment as a parting gift. Thanks a lot \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nyay almost ready and packed!! and my daddy is making me breakfast...this is a great day already! not to mention youre a jerk just played \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Prison Break is slightly less addictive than crack. Watched all of S3 in about three weeks. Sad ending  What show should I start now?\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: So much for working out, was helping my mother find something in a cabinet and stuff fell on my ankle, now I\\'m hobbling along \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @sampan22 post facetime depression sucks!!!!  I sympathize love!\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nto vaughn millls!!! \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @mommystory Bummer - I just read your post and hoped she was doing okay there.  Maybe tomorrow will be better.\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @belu_jb i miss you too! \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Now im not even sure if my ride is coming. Ugh! Mondays \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@SweetSpiced Sounds good!  Can you remember what it\\'s called?  i\\'ll see if i can find it \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: blip.fm is on it\\'s last legs \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nFun nighty-night w/ @willlArd @LeXXtina.. Missin\\' @alabear, SARANGHAE  Beddy-bye, xo!\"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: if lucas till and taylor swift start dating i will start barfing goats all over the placeeeeeeeeeeeeeeeeee   +o(       \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@adrielhampton Yeah...I heard it and wanted to share with @James605 but couldn\\'t remember # either. Too bad audio isn\\'t searchable \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: Oh no....tummyache to the extremeeeee  thank goodness only 7 days!!\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@calvarezHIS Yummmmmm! \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nhmmm i need to find time to go make a poof in my hair.. but hooray for a fabulous school night sleepover at my best friend\\'s house! \"', '\\nGenerate a negative social media tweet on a specific topic. The negative tweet should express convey criticism or disappointment. Model your generated tweets after these examples: @BrandyandIce Chelsea won \"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\n@kimluvsdonnie yay  would love to meet all the Aussies on here\"', '\\nGenerate a positive social media tweet on a specific topic. The positive tweet should express enthusiasm or praise. Model your generated tweets after these examples:\\nI just woke up and...I guess I\\'m going to work on my Temari app. I have strawberry fruit snacks, so I\\'ll eat those for breakfast. \"']🌈 Celebrating the diverse voices that make our community thrive! #unityindiversity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize BERT components\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "# Example training data\n",
    "text = str(sampled_dataset['text'][:120]) + modified_text\n",
    "\n",
    "print(text)\n",
    "\n",
    "labels = np.array([1] * len(sampled_dataset['text'][:20]) + [0] * len(modified_text))\n",
    "labels = np.random.permutation(labels)\n",
    "labels = list(labels[0:len(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e3e8c923-a863-4f69-bbce-3c0cca7aad27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc25f39569d54c0db948a0afbdb1fdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/82 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ba822d5d56444fa99381ba527d5d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'text': text, 'label': labels})\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'])\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "# Tokenize the dataset\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "463e94d2-aed1-4f35-989e-d64f09e4f5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede851f6f2194845af19266e1d7bb5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/82 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26245d8d1fd452197cd91e9392ff5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_labels(example):\n",
    "    example['label'] = torch.tensor(example['label'], dtype=torch.long)\n",
    "    return example\n",
    "\n",
    "train_dataset = train_dataset.map(format_labels)\n",
    "test_dataset = test_dataset.map(format_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8ac5e3e0-c97b-4b23-8724-17b1aa722a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set format for PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps = 20,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "trainer.can_return_loss = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8d2356e5-67f3-4389-b22d-80976daa8b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.556085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.433700</td>\n",
       "      <td>0.640631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "# Save the tokenizer and model\n",
    "tokenizer.save_pretrained('bert_tokenizer')\n",
    "model.save_pretrained('bert_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83acb1b1-e467-4b3f-af7b-830af20e2e40",
   "metadata": {},
   "source": [
    "BERT Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5debaf37-e204-4c43-afac-ace47e136625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1/10) Evaluation: Machine\n",
      "0\n",
      "(2/10) Evaluation: Machine\n",
      "0\n",
      "(3/10) Evaluation: Machine\n",
      "0\n",
      "(4/10) Evaluation: Machine\n",
      "0\n",
      "(5/10) Evaluation: Machine\n",
      "0\n",
      "(6/10) Evaluation: Machine\n",
      "0\n",
      "(7/10) Evaluation: Machine\n",
      "0\n",
      "(8/10) Evaluation: Machine\n",
      "0\n",
      "(9/10) Evaluation: Machine\n",
      "0\n",
      "(10/10) Evaluation: Machine\n",
      "Training accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "training_epochs = 10\n",
    "score = training_epochs\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert_tokenizer')\n",
    "model = BertForSequenceClassification.from_pretrained('bert_model')\n",
    "\n",
    "def evaluate_comment(comment):\n",
    "    global score\n",
    "    inputs = tokenizer(comment, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = softmax(outputs.logits, dim=1)\n",
    "        prediction = torch.argmax(probs, dim=1).item()\n",
    "        print(prediction)\n",
    "    if prediction == 1:\n",
    "        return \"Human\"\n",
    "    else:\n",
    "        score -= 1\n",
    "        return \"Machine\"\n",
    "\n",
    "# Example evaluation\n",
    "for i in range(training_epochs):\n",
    "    new_comment = modified_text[i]\n",
    "    print(\"(\" + str(i+1) + \"/\" + str(training_epochs) + \")\", \"Evaluation:\", evaluate_comment(new_comment))\n",
    "print(\"Training accuracy:\", score/training_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
